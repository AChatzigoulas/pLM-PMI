{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, roc_auc_score, precision_recall_curve, classification_report, matthews_corrcoef, confusion_matrix, precision_recall_curve\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataframe with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>residue_1l</th>\n",
       "      <th>is_IBS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P14555</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P14555</td>\n",
       "      <td>K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P14555</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P14555</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P14555</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325938</th>\n",
       "      <td>P01441</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325939</th>\n",
       "      <td>P01441</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325940</th>\n",
       "      <td>P01441</td>\n",
       "      <td>K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325941</th>\n",
       "      <td>P01441</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325942</th>\n",
       "      <td>P01441</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325943 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uniprot_id residue_1l  is_IBS\n",
       "id                                  \n",
       "0          P14555          M       0\n",
       "1          P14555          K       0\n",
       "2          P14555          T       0\n",
       "3          P14555          L       0\n",
       "4          P14555          L       0\n",
       "...           ...        ...     ...\n",
       "325938     P01441          T       0\n",
       "325939     P01441          D       0\n",
       "325940     P01441          K       0\n",
       "325941     P01441          C       0\n",
       "325942     P01441          N       0\n",
       "\n",
       "[325943 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Datasets/My_Dataset/proteins_df_annotated.csv', index_col=0)\n",
    "df = df[['uniprot_id', 'residue_1l', 'is_IBS']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = ['uniprot_id', 'residue_1l']\n",
    "feat_columns = []\n",
    "\n",
    "# 1024 for protTrans\n",
    "# 1280 for esm\n",
    "for i in range(0,1280):\n",
    "  all_columns.append('Feature_' + str(i + 1))\n",
    "  feat_columns.append('Feature_' + str(i + 1))\n",
    "\n",
    "all_columns.append('is_IBS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./Datasets/My_Dataset/embeddings_esm.json')\n",
    "embeddings_dict = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 443/443 [1:18:09<00:00, 10.59s/it]\n"
     ]
    }
   ],
   "source": [
    "df_embeddings = pd.DataFrame(columns=all_columns)\n",
    "\n",
    "for protein in tqdm(embeddings_dict.keys()):\n",
    "  ibs_values = df[df.uniprot_id == protein].is_IBS.values\n",
    "  temp_df = pd.DataFrame(np.array(embeddings_dict[protein]), columns=feat_columns)\n",
    "  temp_df.insert(0,'uniprot_id',protein)\n",
    "  temp_df.insert(1,'residue_1l',df[df.uniprot_id == protein].residue_1l.tolist())\n",
    "  temp_df['is_IBS'] = ibs_values.tolist()\n",
    "\n",
    "  df_embeddings = pd.concat([df_embeddings, temp_df], ignore_index=True, sort=False)\n",
    "\n",
    "df_embeddings.to_csv('proteins_embeddings_esm_annotated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataframe and set train-test-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>residue_1l</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_1272</th>\n",
       "      <th>Feature_1273</th>\n",
       "      <th>Feature_1274</th>\n",
       "      <th>Feature_1275</th>\n",
       "      <th>Feature_1276</th>\n",
       "      <th>Feature_1277</th>\n",
       "      <th>Feature_1278</th>\n",
       "      <th>Feature_1279</th>\n",
       "      <th>Feature_1280</th>\n",
       "      <th>is_IBS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O01761</td>\n",
       "      <td>M</td>\n",
       "      <td>0.051436</td>\n",
       "      <td>0.057840</td>\n",
       "      <td>-0.002832</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.079338</td>\n",
       "      <td>0.021896</td>\n",
       "      <td>0.050686</td>\n",
       "      <td>-0.112886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033487</td>\n",
       "      <td>-0.214859</td>\n",
       "      <td>-0.042207</td>\n",
       "      <td>0.021364</td>\n",
       "      <td>-0.003393</td>\n",
       "      <td>-0.007095</td>\n",
       "      <td>-0.160942</td>\n",
       "      <td>0.128649</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O01761</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.063363</td>\n",
       "      <td>0.188756</td>\n",
       "      <td>-0.229877</td>\n",
       "      <td>0.050276</td>\n",
       "      <td>0.079548</td>\n",
       "      <td>-0.171778</td>\n",
       "      <td>0.108604</td>\n",
       "      <td>0.039983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197676</td>\n",
       "      <td>-0.114204</td>\n",
       "      <td>-0.001352</td>\n",
       "      <td>0.113371</td>\n",
       "      <td>0.030062</td>\n",
       "      <td>-0.122710</td>\n",
       "      <td>0.157325</td>\n",
       "      <td>0.054761</td>\n",
       "      <td>-0.073914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O01761</td>\n",
       "      <td>S</td>\n",
       "      <td>-0.154245</td>\n",
       "      <td>0.227232</td>\n",
       "      <td>-0.185334</td>\n",
       "      <td>0.012168</td>\n",
       "      <td>0.148100</td>\n",
       "      <td>-0.056722</td>\n",
       "      <td>0.065092</td>\n",
       "      <td>0.031289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081713</td>\n",
       "      <td>-0.119545</td>\n",
       "      <td>0.015701</td>\n",
       "      <td>0.188290</td>\n",
       "      <td>0.227505</td>\n",
       "      <td>-0.060425</td>\n",
       "      <td>0.220450</td>\n",
       "      <td>0.123903</td>\n",
       "      <td>-0.153156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O01761</td>\n",
       "      <td>R</td>\n",
       "      <td>0.036627</td>\n",
       "      <td>0.373738</td>\n",
       "      <td>-0.066661</td>\n",
       "      <td>0.132569</td>\n",
       "      <td>0.077150</td>\n",
       "      <td>-0.188361</td>\n",
       "      <td>-0.010662</td>\n",
       "      <td>0.117254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131667</td>\n",
       "      <td>-0.144065</td>\n",
       "      <td>0.113407</td>\n",
       "      <td>-0.077438</td>\n",
       "      <td>-0.052469</td>\n",
       "      <td>-0.085575</td>\n",
       "      <td>0.224432</td>\n",
       "      <td>-0.196661</td>\n",
       "      <td>-0.248436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O01761</td>\n",
       "      <td>R</td>\n",
       "      <td>-0.054136</td>\n",
       "      <td>0.169932</td>\n",
       "      <td>-0.131501</td>\n",
       "      <td>0.061030</td>\n",
       "      <td>0.031650</td>\n",
       "      <td>-0.164336</td>\n",
       "      <td>0.107642</td>\n",
       "      <td>0.028456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207674</td>\n",
       "      <td>-0.110496</td>\n",
       "      <td>-0.014361</td>\n",
       "      <td>0.091086</td>\n",
       "      <td>0.131275</td>\n",
       "      <td>-0.133346</td>\n",
       "      <td>0.138712</td>\n",
       "      <td>0.026365</td>\n",
       "      <td>-0.135246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325938</th>\n",
       "      <td>P01441</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.063050</td>\n",
       "      <td>-0.156123</td>\n",
       "      <td>-0.024356</td>\n",
       "      <td>0.306045</td>\n",
       "      <td>0.204681</td>\n",
       "      <td>0.126729</td>\n",
       "      <td>0.185344</td>\n",
       "      <td>-0.071489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088493</td>\n",
       "      <td>0.158650</td>\n",
       "      <td>-0.035943</td>\n",
       "      <td>0.039711</td>\n",
       "      <td>-0.132667</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>-0.280772</td>\n",
       "      <td>0.166818</td>\n",
       "      <td>-0.113874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325939</th>\n",
       "      <td>P01441</td>\n",
       "      <td>D</td>\n",
       "      <td>-0.147620</td>\n",
       "      <td>-0.060844</td>\n",
       "      <td>-0.206223</td>\n",
       "      <td>0.033649</td>\n",
       "      <td>0.167042</td>\n",
       "      <td>-0.270832</td>\n",
       "      <td>-0.000974</td>\n",
       "      <td>-0.248665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067822</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>-0.137717</td>\n",
       "      <td>0.053914</td>\n",
       "      <td>0.290871</td>\n",
       "      <td>0.257227</td>\n",
       "      <td>-0.101212</td>\n",
       "      <td>-0.149518</td>\n",
       "      <td>-0.164374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325940</th>\n",
       "      <td>P01441</td>\n",
       "      <td>K</td>\n",
       "      <td>-0.143371</td>\n",
       "      <td>-0.321767</td>\n",
       "      <td>-0.308143</td>\n",
       "      <td>0.256336</td>\n",
       "      <td>-0.222516</td>\n",
       "      <td>-0.122124</td>\n",
       "      <td>0.151273</td>\n",
       "      <td>-0.164138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018976</td>\n",
       "      <td>-0.267598</td>\n",
       "      <td>0.065262</td>\n",
       "      <td>0.133239</td>\n",
       "      <td>0.087251</td>\n",
       "      <td>0.131562</td>\n",
       "      <td>-0.134833</td>\n",
       "      <td>-0.130386</td>\n",
       "      <td>0.114424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325941</th>\n",
       "      <td>P01441</td>\n",
       "      <td>C</td>\n",
       "      <td>0.148909</td>\n",
       "      <td>0.094213</td>\n",
       "      <td>0.298960</td>\n",
       "      <td>0.271658</td>\n",
       "      <td>0.097396</td>\n",
       "      <td>-0.417317</td>\n",
       "      <td>0.205594</td>\n",
       "      <td>-0.042907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127418</td>\n",
       "      <td>-0.341982</td>\n",
       "      <td>-0.366732</td>\n",
       "      <td>0.327198</td>\n",
       "      <td>-0.259981</td>\n",
       "      <td>0.394668</td>\n",
       "      <td>-0.191575</td>\n",
       "      <td>-0.055792</td>\n",
       "      <td>-0.273750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325942</th>\n",
       "      <td>P01441</td>\n",
       "      <td>N</td>\n",
       "      <td>-0.131682</td>\n",
       "      <td>-0.064144</td>\n",
       "      <td>0.094732</td>\n",
       "      <td>0.274434</td>\n",
       "      <td>0.034825</td>\n",
       "      <td>-0.227383</td>\n",
       "      <td>0.225298</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129185</td>\n",
       "      <td>-0.003097</td>\n",
       "      <td>-0.023348</td>\n",
       "      <td>0.345915</td>\n",
       "      <td>-0.164354</td>\n",
       "      <td>0.316149</td>\n",
       "      <td>-0.361902</td>\n",
       "      <td>-0.203341</td>\n",
       "      <td>-0.091843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325943 rows × 1283 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uniprot_id residue_1l  Feature_1  Feature_2  Feature_3  Feature_4  \\\n",
       "0          O01761          M   0.051436   0.057840  -0.002832   0.040003   \n",
       "1          O01761          A  -0.063363   0.188756  -0.229877   0.050276   \n",
       "2          O01761          S  -0.154245   0.227232  -0.185334   0.012168   \n",
       "3          O01761          R   0.036627   0.373738  -0.066661   0.132569   \n",
       "4          O01761          R  -0.054136   0.169932  -0.131501   0.061030   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "325938     P01441          T  -0.063050  -0.156123  -0.024356   0.306045   \n",
       "325939     P01441          D  -0.147620  -0.060844  -0.206223   0.033649   \n",
       "325940     P01441          K  -0.143371  -0.321767  -0.308143   0.256336   \n",
       "325941     P01441          C   0.148909   0.094213   0.298960   0.271658   \n",
       "325942     P01441          N  -0.131682  -0.064144   0.094732   0.274434   \n",
       "\n",
       "        Feature_5  Feature_6  Feature_7  Feature_8  ...  Feature_1272  \\\n",
       "0        0.079338   0.021896   0.050686  -0.112886  ...     -0.033487   \n",
       "1        0.079548  -0.171778   0.108604   0.039983  ...      0.197676   \n",
       "2        0.148100  -0.056722   0.065092   0.031289  ...      0.081713   \n",
       "3        0.077150  -0.188361  -0.010662   0.117254  ...      0.131667   \n",
       "4        0.031650  -0.164336   0.107642   0.028456  ...      0.207674   \n",
       "...           ...        ...        ...        ...  ...           ...   \n",
       "325938   0.204681   0.126729   0.185344  -0.071489  ...      0.088493   \n",
       "325939   0.167042  -0.270832  -0.000974  -0.248665  ...      0.067822   \n",
       "325940  -0.222516  -0.122124   0.151273  -0.164138  ...      0.018976   \n",
       "325941   0.097396  -0.417317   0.205594  -0.042907  ...      0.127418   \n",
       "325942   0.034825  -0.227383   0.225298   0.032520  ...      0.129185   \n",
       "\n",
       "        Feature_1273  Feature_1274  Feature_1275  Feature_1276  Feature_1277  \\\n",
       "0          -0.214859     -0.042207      0.021364     -0.003393     -0.007095   \n",
       "1          -0.114204     -0.001352      0.113371      0.030062     -0.122710   \n",
       "2          -0.119545      0.015701      0.188290      0.227505     -0.060425   \n",
       "3          -0.144065      0.113407     -0.077438     -0.052469     -0.085575   \n",
       "4          -0.110496     -0.014361      0.091086      0.131275     -0.133346   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "325938      0.158650     -0.035943      0.039711     -0.132667      0.230300   \n",
       "325939      0.005815     -0.137717      0.053914      0.290871      0.257227   \n",
       "325940     -0.267598      0.065262      0.133239      0.087251      0.131562   \n",
       "325941     -0.341982     -0.366732      0.327198     -0.259981      0.394668   \n",
       "325942     -0.003097     -0.023348      0.345915     -0.164354      0.316149   \n",
       "\n",
       "        Feature_1278  Feature_1279  Feature_1280  is_IBS  \n",
       "0          -0.160942      0.128649      0.002735       0  \n",
       "1           0.157325      0.054761     -0.073914       0  \n",
       "2           0.220450      0.123903     -0.153156       0  \n",
       "3           0.224432     -0.196661     -0.248436       0  \n",
       "4           0.138712      0.026365     -0.135246       0  \n",
       "...              ...           ...           ...     ...  \n",
       "325938     -0.280772      0.166818     -0.113874       0  \n",
       "325939     -0.101212     -0.149518     -0.164374       0  \n",
       "325940     -0.134833     -0.130386      0.114424       0  \n",
       "325941     -0.191575     -0.055792     -0.273750       0  \n",
       "325942     -0.361902     -0.203341     -0.091843       0  \n",
       "\n",
       "[325943 rows x 1283 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('../Datasets/My_Dataset/proteins_embeddings_esm_annotated.csv', index_col=0)\n",
    "df = pd.read_csv('../Datasets/My_Dataset/proteins_embeddings_protTrans_annotated.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>residue_1l</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O01761</td>\n",
       "      <td>M</td>\n",
       "      <td>0.051436</td>\n",
       "      <td>0.057840</td>\n",
       "      <td>-0.002832</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.079338</td>\n",
       "      <td>0.021896</td>\n",
       "      <td>0.050686</td>\n",
       "      <td>-0.112886</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O01761</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.063363</td>\n",
       "      <td>0.188756</td>\n",
       "      <td>-0.229877</td>\n",
       "      <td>0.050276</td>\n",
       "      <td>0.079548</td>\n",
       "      <td>-0.171778</td>\n",
       "      <td>0.108604</td>\n",
       "      <td>0.039983</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O01761</td>\n",
       "      <td>S</td>\n",
       "      <td>-0.154245</td>\n",
       "      <td>0.227232</td>\n",
       "      <td>-0.185334</td>\n",
       "      <td>0.012168</td>\n",
       "      <td>0.148100</td>\n",
       "      <td>-0.056722</td>\n",
       "      <td>0.065092</td>\n",
       "      <td>0.031289</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O01761</td>\n",
       "      <td>R</td>\n",
       "      <td>0.036627</td>\n",
       "      <td>0.373738</td>\n",
       "      <td>-0.066661</td>\n",
       "      <td>0.132569</td>\n",
       "      <td>0.077150</td>\n",
       "      <td>-0.188361</td>\n",
       "      <td>-0.010662</td>\n",
       "      <td>0.117254</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O01761</td>\n",
       "      <td>R</td>\n",
       "      <td>-0.054136</td>\n",
       "      <td>0.169932</td>\n",
       "      <td>-0.131501</td>\n",
       "      <td>0.061030</td>\n",
       "      <td>0.031650</td>\n",
       "      <td>-0.164336</td>\n",
       "      <td>0.107642</td>\n",
       "      <td>0.028456</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot_id residue_1l  Feature_1  Feature_2  Feature_3  Feature_4  \\\n",
       "0     O01761          M   0.051436   0.057840  -0.002832   0.040003   \n",
       "1     O01761          A  -0.063363   0.188756  -0.229877   0.050276   \n",
       "2     O01761          S  -0.154245   0.227232  -0.185334   0.012168   \n",
       "3     O01761          R   0.036627   0.373738  -0.066661   0.132569   \n",
       "4     O01761          R  -0.054136   0.169932  -0.131501   0.061030   \n",
       "\n",
       "   Feature_5  Feature_6  Feature_7  Feature_8  ...  M  N  P  Q  R  S  T  V  W  \\\n",
       "0   0.079338   0.021896   0.050686  -0.112886  ...  1  0  0  0  0  0  0  0  0   \n",
       "1   0.079548  -0.171778   0.108604   0.039983  ...  0  0  0  0  0  0  0  0  0   \n",
       "2   0.148100  -0.056722   0.065092   0.031289  ...  0  0  0  0  0  1  0  0  0   \n",
       "3   0.077150  -0.188361  -0.010662   0.117254  ...  0  0  0  0  1  0  0  0  0   \n",
       "4   0.031650  -0.164336   0.107642   0.028456  ...  0  0  0  0  1  0  0  0  0   \n",
       "\n",
       "   Y  \n",
       "0  0  \n",
       "1  0  \n",
       "2  0  \n",
       "3  0  \n",
       "4  0  \n",
       "\n",
       "[5 rows x 1303 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert residues to one-hot encode\n",
    "df_res = pd.get_dummies(df['residue_1l'])\n",
    "df = df.merge(df_res, left_index=True, right_index=True, how='inner')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of proteins 443 \n"
     ]
    }
   ],
   "source": [
    "print('Total number of proteins %d ' % len(df.uniprot_id.unique()))\n",
    "\n",
    "# for proteins that do not belong to Peprmint dataset and belong to Dreamm dataset (so we don't have a lot of information) will become the evaluation dataset\n",
    "uniprot_id_val = ['P61914', 'Q15075', 'O16025', 'Q96QK1', 'Q960X8', 'P12530', 'P00735', 'P40343', 'O24592', 'P05979', 'O88339', 'P22637', 'Q28175', 'P08684', 'P0C2E9', 'Q9LCB2', 'P60484', 'P0C216', 'Q02127', 'P20932', 'P02749', 'P11889', 'Q77DJ6', 'P00803', 'Q99685', 'P49638', 'Q9NZD2', 'P00720', 'P12724', 'P12104', 'P56254', 'P60980', 'P01441']\n",
    "df_val = df[df.uniprot_id.isin(uniprot_id_val)]\n",
    "\n",
    "f = open('../Datasets/My_Dataset/split_proteins.json')\n",
    "dict_proteins_split = json.load(f)\n",
    "f.close()\n",
    "\n",
    "df_train = df[df.uniprot_id.isin(dict_proteins_split['train'])]\n",
    "df_test = df[df.uniprot_id.isin(dict_proteins_split['test'])]\n",
    "df_val = df[df.uniprot_id.isin(dict_proteins_split['val'])]\n",
    "\n",
    "X_train, y_train = df_train.drop(['uniprot_id', 'residue_1l', 'is_IBS'], axis=1, inplace=False), df_train['is_IBS']\n",
    "X_test, y_test = df_test.drop(['uniprot_id', 'residue_1l', 'is_IBS'], axis=1, inplace=False), df_test['is_IBS']\n",
    "X_val, y_val = df_val.drop(['uniprot_id', 'residue_1l', 'is_IBS'], axis=1, inplace=False), df_val['is_IBS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of Amino acids')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.is_IBS.value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\n",
    "plt.xlabel(\"Is IBS?\", labelpad=14)\n",
    "plt.ylabel(\"Number of Amino acids\", labelpad=14)\n",
    "# observe a totally imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio is 34.766963\n",
      "5.896351704772326\n"
     ]
    }
   ],
   "source": [
    "ratio = df_train.is_IBS.value_counts()[0]/df_train.is_IBS.value_counts()[1]\n",
    "print(df_train.is_IBS.value_counts())\n",
    "print(\"Ratio is %f\" % ratio)\n",
    "print(np.sqrt(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.drop(['uniprot_id', 'residue_1l', 'is_IBS'], axis=1, inplace=False), df_train['is_IBS']\n",
    "X_test, y_test = df_test.drop(['uniprot_id', 'residue_1l', 'is_IBS'], axis=1, inplace=False), df_test['is_IBS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train\n",
    "del df_test\n",
    "del df\n",
    "del df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51438147 17.88348171]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import compute_class_weight\n",
    "print(compute_class_weight('balanced', classes=[0, 1], y=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.297 \n",
      "MCC: 0.314 \n",
      "Balanced accuracy: 0.589 \n",
      "       0    1\n",
      "0  11953  168\n",
      "1   1310  312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = XGBClassifier(objective='binary:logistic', scale_pos_weight=np.sqrt(ratio), random_state=0, n_jobs=7)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "ypred = clf.predict(X_test)\n",
    "\n",
    "print('F1 score: %.3f ' % f1_score(y_test, ypred))\n",
    "print('MCC: %.3f ' % matthews_corrcoef(y_test, ypred))\n",
    "print('Balanced accuracy: %.3f ' % balanced_accuracy_score(y_test, ypred))\n",
    "\n",
    "cm = confusion_matrix(y_test, ypred)\n",
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])\n",
    "print(cm)\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.heatmap(cm, cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='',xticklabels = ['no_IBS', 'IBS'],yticklabels = ['no_IBS', 'IBS'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total fit time: ~10m - protTrans\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0lax\" rowspan=\"2\"></th>\n",
    "    <th class=\"tg-uca5\" colspan=\"3\">scale_pos_weight</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th class=\"tg-8zwo\">34.7 sum(neg)/sum(pos)</th>\n",
    "    <th class=\"tg-8zwo\"><span style=\"font-weight:400;font-style:normal\">48</span></th>\n",
    "    <th class=\"tg-8zwo\">30</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-1wig\">F1_score</td>\n",
    "    <td class=\"tg-0lax\">0.581</td>\n",
    "    <td class=\"tg-0lax\">0.571</td>\n",
    "    <td class=\"tg-0lax\">0.578</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-1wig\">MCC</td>\n",
    "    <td class=\"tg-0lax\">0.522</td>\n",
    "    <td class=\"tg-0lax\">0.511</td>\n",
    "    <td class=\"tg-0lax\">0.519</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-1wig\">Balanced_acc</td>\n",
    "    <td class=\"tg-0lax\">0.785</td>\n",
    "    <td class=\"tg-0lax\">0.79</td>\n",
    "    <td class=\"tg-0lax\">0.783</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\"></td>\n",
    "    <td class=\"tg-0lax\">Best FP (941) FN (573)</td>\n",
    "    <td class=\"tg-0lax\">A lot FP (1097)</td>\n",
    "    <td class=\"tg-0lax\">less FP than 34 (947)</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "Total fit time: ~10m - ESM\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0lax\" rowspan=\"2\"></th>\n",
    "    <th class=\"tg-uca5\" colspan=\"1\">scale_pos_weight</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th class=\"tg-8zwo\">34.7 sum(neg)/sum(pos)</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-1wig\">F1_score</td>\n",
    "    <td class=\"tg-0lax\">0.418</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-1wig\">MCC</td>\n",
    "    <td class=\"tg-0lax\">0.365</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-1wig\">Balanced_acc</td>\n",
    "    <td class=\"tg-0lax\">0.653</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\"></td>\n",
    "    <td class=\"tg-0lax\">FP (526) FN (1055)</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced', random_state=0, n_jobs=6) # try also -> balanced_subsample\n",
    "\n",
    "# fit the predictor and target\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# evaluate model on the traindataset\n",
    "ypred = rfc.predict(X_test)\n",
    "\n",
    "print('F1 score: %.3f ' % f1_score(y_test, ypred))\n",
    "print('MCC: %.3f ' % matthews_corrcoef(y_test, ypred))\n",
    "print('Balanced accuracy: %.3f ' % balanced_accuracy_score(y_test, ypred))\n",
    "print('Accuracy: %.3f ' % accuracy_score(y_test, ypred))\n",
    "print('ROC : %.3f ' % roc_auc_score(y_test, rfc.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "cm = confusion_matrix(y_test, ypred)\n",
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbfc = BalancedRandomForestClassifier(random_state=0, n_jobs=6)\n",
    "\n",
    "# fit the predictor and target\n",
    "rbfc.fit(X_train, y_train)\n",
    "\n",
    "# evaluate model on the traindataset\n",
    "ypred = rbfc.predict(X_test)\n",
    "\n",
    "print('F1 score: %.3f ' % f1_score(y_test, ypred))\n",
    "print('MCC: %.3f ' % matthews_corrcoef(y_test, ypred))\n",
    "print('Balanced accuracy: %.3f ' % balanced_accuracy_score(y_test, ypred))\n",
    "print('Accuracy: %.3f ' % accuracy_score(y_test, ypred))\n",
    "print('ROC : %.3f ' % roc_auc_score(y_test, rbfc.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "cm = confusion_matrix(y_test, ypred)\n",
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])\n",
    "print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total fit time ~1-3m - protTrans\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th rowspan=\"2\"></th>\n",
    "    <th colspan=\"3\">Randomforest</th>\n",
    "    <th colspan=\"3\">BalancedRandomForest</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>'balanced' class weight</th>\n",
    "    <th>'balanced_subsample' class weight</th>\n",
    "    <th>nothing</th>\n",
    "    <th>n_estimators = 150</th>\n",
    "    <th>n_estimators = 1000</th>\n",
    "    <th>'balanced' class weight</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>F1_score</td>\n",
    "    <td>0.0</td>\n",
    "    <td>0.0</td>\n",
    "    <td>0.0</td>\n",
    "    <td>0.487</td>\n",
    "    <td>0.493</td>\n",
    "    <td>0.446</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>MCC</td>\n",
    "    <td>0.0</td>\n",
    "    <td>0.0</td>\n",
    "    <td>0.023</td>\n",
    "    <td>0.429</td>\n",
    "    <td>0.437</td>\n",
    "    <td>0.365</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Balanced_acc</td>\n",
    "    <td>0.5</td>\n",
    "    <td>0.5</td>\n",
    "    <td>0.5</td>\n",
    "    <td>0.788</td>\n",
    "    <td>0.793</td>\n",
    "    <td>0.716</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>ROC auc</td>\n",
    "    <td>0.842</td>\n",
    "    <td>0.841</td>\n",
    "    <td>0.795</td>\n",
    "    <td>0.866</td>\n",
    "    <td>0.872</td>\n",
    "    <td>0.824</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>All FN and no TP</td>\n",
    "    <td>All FN and no TP</td>\n",
    "    <td>All FN and 1 TP</td>\n",
    "    <td>A lot FP (2194)</td>\n",
    "    <td>Not many FP (1520) FN (719)</td>\n",
    "    <td>FP (1520) & FN (719)</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "Total fit time ~1-3m - ESM\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th rowspan=\"2\"></th>\n",
    "    <th colspan=\"3\">Randomforest</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>'balanced' class weight</th>\n",
    "    <th>class weight = {}</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>F1_score</td>\n",
    "    <td>0.</td>\n",
    "    <td>0.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>MCC</td>\n",
    "    <td>0.</td>\n",
    "    <td>0.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Balanced_acc</td>\n",
    "    <td>0.</td>\n",
    "    <td>0.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>All FN and no TP</td>\n",
    "    <td>All FN and no TP</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = svm.SVC(kernel='linear', C = 100, random_state=0)\n",
    "\n",
    "clf_svc.fit(X_train, y_train)\n",
    "\n",
    "# evaluate model on the traindataset\n",
    "ypred = clf_svc.predict(X_test)\n",
    "\n",
    "print('F1 score: %.3f ' % f1_score(y_test, ypred))\n",
    "print('MCC: %.3f ' % matthews_corrcoef(y_test, ypred))\n",
    "print('Balanced accuracy: %.3f ' % balanced_accuracy_score(y_test, ypred))\n",
    "print('Accuracy: %.3f ' % accuracy_score(y_test, ypred))\n",
    "print('ROC : %.3f ' % roc_auc_score(y_test, clf_svc.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "cm = confusion_matrix(y_test, ypred)\n",
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wclf_svc = svm.SVC(kernel='linear', class_weight='balanced', # penalize  class_weight={1: 100},\n",
    "                  probability=True, random_state=0)\n",
    "\n",
    "wclf_svc.fit(X_train, y_train)\n",
    "\n",
    "# evaluate model on the traindataset\n",
    "ypred = wclf_svc.predict(X_test)\n",
    "\n",
    "print('F1 score: %.3f ' % f1_score(y_test, ypred))\n",
    "print('MCC: %.3f ' % matthews_corrcoef(y_test, ypred))\n",
    "print('Balanced accuracy: %.3f ' % balanced_accuracy_score(y_test, ypred))\n",
    "print('Accuracy: %.3f ' % accuracy_score(y_test, ypred))\n",
    "print('ROC : %.3f ' % roc_auc_score(y_test, wclf_svc.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "cm = confusion_matrix(y_test, ypred)\n",
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])\n",
    "print(cm)\n",
    "# 4.730m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.478 \n",
      "MCC: 0.407 \n",
      "Balanced accuracy: 0.753 \n",
      "       0     1\n",
      "0  10402  1719\n",
      "1    572  1050\n"
     ]
    }
   ],
   "source": [
    "clf = Perceptron(random_state=0, class_weight={0:1, 1:33}, n_jobs=6)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "ypred = clf.predict(X_test)\n",
    "\n",
    "print('F1 score: %.3f ' % f1_score(y_test, ypred))\n",
    "print('MCC: %.3f ' % matthews_corrcoef(y_test, ypred))\n",
    "print('Balanced accuracy: %.3f ' % balanced_accuracy_score(y_test, ypred))\n",
    "\n",
    "cm = confusion_matrix(y_test, ypred)\n",
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])\n",
    "print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total fit time: 3m - protTrans\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "  <th> </th>\n",
    "    <th>'balanced' class weight</th>\n",
    "    <th>{0:1, 1:30}</th>\n",
    "    <th>{0:1, 1:34.7}</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>F1_score</td>\n",
    "    <td>0.477</td>\n",
    "    <td>0.473</td>\n",
    "    <td>0.484</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>MCC</td>\n",
    "    <td>0.387</td>\n",
    "    <td>0.404</td>\n",
    "    <td>0.421</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Balanced_acc</td>\n",
    "    <td>0.771</td>\n",
    "    <td>0.76</td>\n",
    "    <td>0.776</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>Many FP (2679) and less FN (385)</td>\n",
    "    <td>FP (1949) and less FN (517)</td>\n",
    "    <td>Many FP (2040) and less FN (453)</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "Total fit time: 3m - ESM\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "  <th> </th>\n",
    "    <th>'balanced' class weight</th>\n",
    "    <th>{0:1, 1:33}</th>\n",
    "    <th>{0:1, 1:34.7}</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>F1_score</td>\n",
    "    <td>0.</td>\n",
    "    <td>0.478</td>\n",
    "    <td>0.409</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>MCC</td>\n",
    "    <td>0.</td>\n",
    "    <td>0.407</td>\n",
    "    <td>0.350</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Balanced_acc</td>\n",
    "    <td>0.</td>\n",
    "    <td>0.753</td>\n",
    "    <td>0.757</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>Many FP () and less FN ()</td>\n",
    "    <td>FP (1719) and less FN (572)</td>\n",
    "    <td>Many FP (3375) and less FN (337)</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 16)                20816     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,833\n",
      "Trainable params: 20,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(16, activation='relu',input_shape=(X_train.shape[-1],)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation='sigmoid', bias_initializer=None),\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=keras.metrics.BinaryAccuracy(name='accuracy'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 15:56:54.652721: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 2s 10ms/step - loss: 0.1064 - accuracy: 0.9720\n",
      "Epoch 2/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0719 - accuracy: 0.9743\n",
      "Epoch 3/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0622 - accuracy: 0.9769\n",
      "Epoch 4/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0575 - accuracy: 0.9781\n",
      "Epoch 5/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0546 - accuracy: 0.9790\n",
      "Epoch 6/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0525 - accuracy: 0.9799\n",
      "Epoch 7/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0506 - accuracy: 0.9804\n",
      "Epoch 8/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0495 - accuracy: 0.9809\n",
      "Epoch 9/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0486 - accuracy: 0.9813\n",
      "Epoch 10/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0471 - accuracy: 0.9817\n",
      "Epoch 11/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0469 - accuracy: 0.9817\n",
      "Epoch 12/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0462 - accuracy: 0.9822\n",
      "Epoch 13/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0453 - accuracy: 0.9826\n",
      "Epoch 14/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0451 - accuracy: 0.9825\n",
      "Epoch 15/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0440 - accuracy: 0.9828\n",
      "Epoch 16/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0433 - accuracy: 0.9832\n",
      "Epoch 17/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0429 - accuracy: 0.9832\n",
      "Epoch 18/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0431 - accuracy: 0.9833\n",
      "Epoch 19/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0420 - accuracy: 0.9836\n",
      "Epoch 20/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0415 - accuracy: 0.9839\n",
      "Epoch 21/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0414 - accuracy: 0.9840\n",
      "Epoch 22/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0404 - accuracy: 0.9844\n",
      "Epoch 23/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0401 - accuracy: 0.9845\n",
      "Epoch 24/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0402 - accuracy: 0.9845\n",
      "Epoch 25/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0395 - accuracy: 0.9847\n",
      "Epoch 26/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0394 - accuracy: 0.9847\n",
      "Epoch 27/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0391 - accuracy: 0.9847\n",
      "Epoch 28/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0387 - accuracy: 0.9850\n",
      "Epoch 29/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0387 - accuracy: 0.9848\n",
      "Epoch 30/30\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.0388 - accuracy: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x309259820>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_for_0 = (1 / y_train.value_counts()[0]) * (y_train.count() / 2.0)\n",
    "weight_for_1 = (1 / y_train.value_counts()[1]) * (y_train.count() / 2.0)\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=class_weight\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84/430 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 15:57:43.812063: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/430 [==============================] - 1s 2ms/step\n",
      "F1 score: 0.433 \n",
      "MCC: 0.452 \n",
      "Balanced accuracy: 0.666 \n",
      "       0    1\n",
      "0  11872  249\n",
      "1   1050  572\n"
     ]
    }
   ],
   "source": [
    "ypred = model.predict(X_test)\n",
    "\n",
    "print('F1 score: %.3f ' % f1_score(y_test, ypred > 0.58))\n",
    "print('MCC: %.3f ' % matthews_corrcoef(y_test, ypred > 0.5))\n",
    "print('Balanced accuracy: %.3f ' % balanced_accuracy_score(y_test, ypred > 0.5))\n",
    "\n",
    "cm = confusion_matrix(y_test, ypred > 0.5)\n",
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])\n",
    "print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total fit time -> 50 epochs - 1m30s - protTrans\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "  <th> </th>\n",
    "    <th>With class weight</th>\n",
    "    <th>Without class weight</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>F1_score</td>\n",
    "    <td>0.581</td>\n",
    "    <td>0.582</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>MCC</td>\n",
    "    <td>0.526</td>\n",
    "    <td>0.549</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Balanced_acc</td>\n",
    "    <td>0.809</td>\n",
    "    <td>0.733</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>FP (1229) - FN (455)</td>\n",
    "    <td>FP (323) - FN (823)</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "Total fit time -> 50 epochs - 1m30s - ESM\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "  <th> </th>\n",
    "    <th>With class weight</th>\n",
    "    <th>Without class weight</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>F1_score</td>\n",
    "    <td>0.496</td>\n",
    "    <td>0.433</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>MCC</td>\n",
    "    <td>0.425</td>\n",
    "    <td>0.452</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Balanced_acc</td>\n",
    "    <td>0.781</td>\n",
    "    <td>0.666</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>FP (2089) - FN (432)</td>\n",
    "    <td>FP (209) - FN (1150)</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.524 \n",
      "MCC: 0.511 \n",
      "Balanced accuracy: 0.693 \n",
      "      0    1\n",
      "0  6795  117\n",
      "1   516  348\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=300, hidden_layer_sizes=(100,)).fit(X_train, y_train)\n",
    "\n",
    "ypred = clf.predict(X_test)\n",
    "\n",
    "print('F1 score: %.3f ' % f1_score(y_test, ypred))\n",
    "print('MCC: %.3f ' % matthews_corrcoef(y_test, ypred))\n",
    "print('Balanced accuracy: %.3f ' % balanced_accuracy_score(y_test, ypred))\n",
    "\n",
    "cm = confusion_matrix(y_test, ypred)\n",
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])\n",
    "print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total time: ~60m - protTRans\n",
    "\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "  <th> </th>\n",
    "    <th>100 hiden layer / 0.001 lr / Adams / relu</th>\n",
    "    <th>50 hiden layer / 0.001 lr / Adams / relu</th>\n",
    "    <th>150 hiden layer / 0.001 lr / Adams / relu</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>F1_score</td>\n",
    "    <td>0.619</td>\n",
    "    <td>0.601</td>\n",
    "    <td>0.627</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>MCC</td>\n",
    "    <td>0.577</td>\n",
    "    <td>0.556</td>\n",
    "    <td>0.586</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Balanced_acc</td>\n",
    "    <td>0.766</td>\n",
    "    <td>0.755</td>\n",
    "    <td>0.770</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>ROC auc</td>\n",
    "    <td>0.909</td>\n",
    "    <td>0.902</td>\n",
    "    <td>0.911</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>Less FP (426) and more FN (703)</td>\n",
    "    <td>FP (445) - FN (735)</td>\n",
    "    <td>FP (419) - FN (689)</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 256)               333056    \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 957,441\n",
      "Trainable params: 957,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 19:54:38.060883: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 4s 23ms/step - loss: 0.2597 - accuracy: 0.8852\n",
      "Epoch 2/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.1182 - accuracy: 0.9452\n",
      "Epoch 3/30\n",
      "146/146 [==============================] - 3s 21ms/step - loss: 0.0863 - accuracy: 0.9573\n",
      "Epoch 4/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0673 - accuracy: 0.9670\n",
      "Epoch 5/30\n",
      "146/146 [==============================] - 3s 21ms/step - loss: 0.0566 - accuracy: 0.9730\n",
      "Epoch 6/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0531 - accuracy: 0.9746\n",
      "Epoch 7/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0451 - accuracy: 0.9779\n",
      "Epoch 8/30\n",
      "146/146 [==============================] - 3s 21ms/step - loss: 0.0415 - accuracy: 0.9806\n",
      "Epoch 9/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0371 - accuracy: 0.9831\n",
      "Epoch 10/30\n",
      "146/146 [==============================] - 3s 21ms/step - loss: 0.0322 - accuracy: 0.9852\n",
      "Epoch 11/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0283 - accuracy: 0.9867\n",
      "Epoch 12/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0296 - accuracy: 0.9863\n",
      "Epoch 13/30\n",
      "146/146 [==============================] - 3s 21ms/step - loss: 0.0263 - accuracy: 0.9882\n",
      "Epoch 14/30\n",
      "146/146 [==============================] - 3s 21ms/step - loss: 0.0256 - accuracy: 0.9885\n",
      "Epoch 15/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0236 - accuracy: 0.9895\n",
      "Epoch 16/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0239 - accuracy: 0.9885\n",
      "Epoch 17/30\n",
      "146/146 [==============================] - 3s 21ms/step - loss: 0.0263 - accuracy: 0.9886\n",
      "Epoch 18/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0238 - accuracy: 0.9893\n",
      "Epoch 19/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0206 - accuracy: 0.9913\n",
      "Epoch 20/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0257 - accuracy: 0.9883\n",
      "Epoch 21/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0179 - accuracy: 0.9917\n",
      "Epoch 22/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0131 - accuracy: 0.9943\n",
      "Epoch 23/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0152 - accuracy: 0.9936\n",
      "Epoch 24/30\n",
      "146/146 [==============================] - 3s 21ms/step - loss: 0.0129 - accuracy: 0.9945\n",
      "Epoch 25/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0367 - accuracy: 0.9862\n",
      "Epoch 26/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0279 - accuracy: 0.9894\n",
      "Epoch 27/30\n",
      "146/146 [==============================] - 3s 21ms/step - loss: 0.0175 - accuracy: 0.9921\n",
      "Epoch 28/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0138 - accuracy: 0.9938\n",
      "Epoch 29/30\n",
      "146/146 [==============================] - 3s 21ms/step - loss: 0.0132 - accuracy: 0.9942\n",
      "Epoch 30/30\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 0.0134 - accuracy: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3574eb700>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation='relu',input_shape=(X_train.shape[-1],)),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid', bias_initializer=None),\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=keras.metrics.BinaryAccuracy(name='accuracy'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "weight_for_0 = (1 / y_train.value_counts()[0]) * (y_train.count() / 2.0)\n",
    "weight_for_1 = (1 / y_train.value_counts()[1]) * (y_train.count() / 2.0)\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=class_weight\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 1s 3ms/step\n",
      "Best Threshold=0.224931, F-Score=0.580\n",
      "F1 score: 0.571 \n",
      "MCC: 0.521 \n",
      "      0    1\n",
      "0  6597  315\n",
      "1   393  471\n"
     ]
    }
   ],
   "source": [
    "ypred = model.predict(X_test)\n",
    "\n",
    "print('F1 score: %.3f ' % f1_score(y_test, ypred > 0.5))\n",
    "print('MCC: %.3f ' % matthews_corrcoef(y_test, ypred > 0.5))\n",
    "\n",
    "cm = confusion_matrix(y_test, ypred > 0.5)\n",
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])\n",
    "print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total time: ~1m30s - ESM\n",
    "\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "  <th> </th>\n",
    "    <th>3 hiden layer / 0.001 lr / Adams / relu</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>F1_score</td>\n",
    "    <td>0.553</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>MCC</td>\n",
    "    <td>0.492</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Balanced_acc</td>\n",
    "    <td>0.753</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>Less FP (693) and more FN (807)</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5143814688061236, 1: 17.883481713185756}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "class_weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a5edab282632443219e051e4ade2d1d5bbc671c781051bf1437897cbdfea0f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
